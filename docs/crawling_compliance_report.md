# ev_crawler.py 크롤링 준수 검토 보고서

## 개요
본 보고서는 `ev_crawler.py`의 법적/윤리적 준수 여부를 principle.md 체크리스트 기반으로 분석한 결과입니다.

---

## 1. 공식 제공 채널 우선 사용 여부

**상태: 해당 없음 (웹 크롤링이 유일한 수집 방법)**

### 확인 결과
- data.go.kr 검토: 전기차 충전기 보급 현황 API만 존재
- 보조금 지급 현황(민간공고대수, 접수대수, 출고대수 등) API는 제공되지 않음
- 따라서 ev.or.kr 웹 크롤링이 해당 데이터를 수집할 수 있는 유일한 방법

---

## 2. 접근통제 우회 여부

**상태: 준수**

| 항목 | 확인 결과 |
|------|----------|
| 로그인 우회 | 없음 (공개 페이지 접근) |
| 캡차(CAPTCHA) 우회 | 없음 |
| 토큰/세션 우회 | 없음 |
| 인증 우회 | 없음 |

### 분석
- 크롤링 대상 URL: `https://ev.or.kr/nportal/buySupprt/initSubsidyPaymentCheckAction.do`
- 해당 페이지는 로그인 없이 누구나 접근 가능한 공개 페이지
- 어떠한 인증 절차도 우회하지 않음

---

## 3. 차단 회피 여부

**상태: 준수**

| 항목 | 확인 결과 |
|------|----------|
| IP 변경/로테이션 | 없음 |
| 프록시 사용 | 없음 |
| User-Agent 위조 | 없음 (기본 브라우저 UA 사용) |

### 분석
- 단일 IP에서 정상적인 브라우저 접근 방식 사용
- 차단 우회를 위한 어떠한 기법도 사용하지 않음

---

## 4. 서버 부하 최소화

**상태: 준수**

### 구현된 부하 방지 조치
1. **적절한 대기 시간**
   - 페이지 로드 후 2초 대기: `page.wait_for_timeout(2000)`
   - 버튼 클릭 후 1초 대기: `page.wait_for_timeout(1000)`

2. **최소한의 요청**
   - 하루 4회 실행 (cron 스케줄 기준)
   - 단일 실행으로 필요한 데이터만 수집
   - 불필요한 반복 요청 없음

3. **효율적인 데이터 수집**
   - 필요한 페이지만 접근 (차종별 2회 버튼 클릭)
   - 대량 요청이나 무한 루프 없음

---

## 5. 개인정보 수집 여부

**상태: 준수**

### 수집 데이터 목록
- 시도 (행정구역)
- 지역구분
- 차종구분
- 공고파일 링크
- 접수방법
- 민간공고대수 (전체/우선순위/법인기관/택시/일반)
- 접수대수 (전체/우선순위/법인기관/택시/일반)
- 출고대수 (전체/우선순위/법인기관/택시/일반)
- 출고잔여대수 (전체/우선순위/법인기관/택시/일반)
- 비고

### 개인정보 수집 여부
| 개인정보 유형 | 수집 여부 |
|--------------|----------|
| 이름 | 수집 안 함 |
| 전화번호 | 수집 안 함 |
| 이메일 | 수집 안 함 |
| 주소 | 수집 안 함 |
| 차량번호 | 수집 안 함 |
| 차량식별정보 | 수집 안 함 |

---

## 6. 재배포/상업적 이용

**상태: 법적으로 허용**

### 법적 근거
- **공공데이터법 제3조**: 공공데이터의 영리적 이용을 원칙적으로 허용
- 환경부 무공해차 통합누리집은 공공기관이 운영하는 사이트
- 수집 데이터는 공공 보조금 현황 정보로 공익적 성격

### 사용 목적
- 자동차 제조회사에서 고객에게 보조금 정보 제공
- 데이터 자체를 판매하는 것이 아닌 정보 제공 목적

### 권장사항
- 출처 표시 추가: "데이터 출처: 환경부 무공해차 통합누리집(ev.or.kr)"

---

## 7. robots.txt 준수

**상태: 확인 필요 (코드에 검증 로직 추가됨)**

### 현재 상황
- `https://ev.or.kr/robots.txt` 접근 시 400 에러 반환
- robots.txt 파일이 설정되지 않은 것으로 추정
- robots.txt 미설정 시 모든 크롤링이 허용된 것으로 해석

### 코드 개선
- robots.txt 확인 로직이 `check_robots_txt()` 함수로 추가됨
- 크롤링 시작 전 자동으로 robots.txt 확인
- 명시적 Disallow 시 경고 출력

---

## 결론

### 준수 현황 요약

| 체크 항목 | 상태 |
|----------|------|
| 공식 API 우선 사용 | 해당 없음 (API 미제공) |
| 접근통제 우회 금지 | 준수 |
| 차단 회피 금지 | 준수 |
| 서버 부하 최소화 | 준수 |
| 개인정보 수집 금지 | 준수 |
| 재배포/상업적 이용 | 법적 허용 |
| robots.txt 준수 | 확인 로직 추가됨 |

### 최종 판단
`ev_crawler.py`는 principle.md의 크롤링 원칙을 준수하고 있으며, 법적/윤리적으로 문제가 없는 것으로 판단됩니다.

---

## 개선 이력

| 날짜 | 개선 내용 |
|------|----------|
| 2025-01-22 | robots.txt 확인 로직 추가 |
| 2025-01-22 | CSV 출처 표시 추가 |
| 2025-01-22 | 준수 검토 보고서 작성 |

---

*본 보고서는 principle.md 체크리스트 기반으로 작성되었습니다.*
